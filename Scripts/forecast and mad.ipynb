{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 730 days of sample data...\n",
      "Sample data generation complete.\n",
      "\n",
      "Training SARIMA model to forecast alerts for the next 30 days...\n",
      "Alert forecasting complete.\n",
      "\n",
      "Modeling alert-to-case conversion rate...\n",
      "Learned Conversion Rate: 4.98%\n",
      "Predicting future cases based on forecasted alerts...\n",
      "Case prediction complete.\n",
      "\n",
      "--- Forecast Results ---\n",
      "            Forecasted_Alerts  Forecasted_Cases\n",
      "2024-12-31                370                17\n",
      "2025-01-01                351                16\n",
      "2025-01-02                388                18\n",
      "2025-01-03                337                16\n",
      "2025-01-04                258                12\n",
      "2025-01-05                243                11\n",
      "2025-01-06                351                16\n",
      "2025-01-07                380                18\n",
      "2025-01-08                355                17\n",
      "2025-01-09                386                18\n",
      "2025-01-10                328                15\n",
      "2025-01-11                256                12\n",
      "2025-01-12                265                12\n",
      "2025-01-13                352                17\n",
      "2025-01-14                377                18\n",
      "2025-01-15                355                17\n",
      "2025-01-16                389                18\n",
      "2025-01-17                335                16\n",
      "2025-01-18                260                12\n",
      "2025-01-19                255                12\n",
      "2025-01-20                354                17\n",
      "2025-01-21                381                18\n",
      "2025-01-22                358                17\n",
      "2025-01-23                390                18\n",
      "2025-01-24                334                16\n",
      "2025-01-25                260                12\n",
      "2025-01-26                263                12\n",
      "2025-01-27                355                17\n",
      "2025-01-28                381                18\n",
      "2025-01-29                359                17\n",
      "\n",
      "------------------------\n",
      "\n",
      "Generating forecast plot...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'seaborn-v0_8-whitegrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/style/core.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrc_params_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_default_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36mrc_params_from_file\u001b[0;34m(fname, fail_on_error, use_default_template)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \"\"\"\n\u001b[0;32m--> 874\u001b[0;31m     \u001b[0mconfig_from_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfail_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfail_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0mrc_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_or_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-v0_8-whitegrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c74a86e96bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# 5. Plot the forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mplot_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistorical_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_cases_forecast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c74a86e96bd3>\u001b[0m in \u001b[0;36mplot_forecast\u001b[0;34m(historical_cases, forecasted_cases)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \"\"\"\n\u001b[1;32m    154\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating forecast plot...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seaborn-v0_8-whitegrid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/style/core.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 raise IOError(\n\u001b[0m\u001b[1;32m    125\u001b[0m                     \u001b[0;34m\"{!r} not found in the style library and input is not a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0;34m\"valid URL or path; see `style.available` for list of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: 'seaborn-v0_8-whitegrid' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# You can adjust these parameters to fit your specific needs.\n",
    "DATA_PERIOD_DAYS = 365 * 2 # How many days of historical data to generate.\n",
    "FORECAST_PERIOD_DAYS = 30  # How many days into the future to forecast.\n",
    "ALERT_TO_CASE_LAG_DAYS = 1 # The typical delay (in days) for an alert to become a case.\n",
    "BASE_CONVERSION_RATE = 0.05 # ~5% of alerts become cases.\n",
    "WEEKLY_SEASONALITY = True   # Set to True if you expect weekly patterns (e.g., fewer alerts on weekends).\n",
    "\n",
    "# --- 1. Generate Realistic Sample Data ---\n",
    "# In a real-world scenario, you would replace this section with your own data loading logic.\n",
    "# For example: df = pd.read_csv('your_data.csv', parse_dates=['date_column'])\n",
    "def generate_sample_data():\n",
    "    \"\"\"\n",
    "    Creates a sample DataFrame with 'date', 'alerts', and 'cases' columns.\n",
    "    This simulates a year of historical data with trends and seasonality.\n",
    "    \"\"\"\n",
    "    print(f\"Generating {DATA_PERIOD_DAYS} days of sample data...\")\n",
    "    \n",
    "    # Create a date range\n",
    "    start_date = pd.to_datetime('2023-01-01')\n",
    "    dates = pd.date_range(start_date, periods=DATA_PERIOD_DAYS, freq='D')\n",
    "    \n",
    "    # Generate alerts data\n",
    "    # Base alerts + some noise + a slight upward trend + weekly seasonality\n",
    "    base_alerts = 200\n",
    "    noise = np.random.randint(-50, 50, size=DATA_PERIOD_DAYS)\n",
    "    trend = np.arange(DATA_PERIOD_DAYS) * 0.2\n",
    "    \n",
    "    alerts = base_alerts + noise + trend\n",
    "    \n",
    "    # Add weekly seasonality (e.g., fewer alerts on weekends)\n",
    "    if WEEKLY_SEASONALITY:\n",
    "        day_of_week_effect = [0, 0, 0, 0, -20, -80, -90] # Mon=0, Tue=1... Sat=5, Sun=6\n",
    "        seasonality = [day_of_week_effect[d.weekday()] for d in dates]\n",
    "        alerts += seasonality\n",
    "\n",
    "    # Ensure alerts are non-negative\n",
    "    alerts = np.maximum(0, alerts).astype(int)\n",
    "\n",
    "    # Generate cases data based on lagged alerts and conversion rate\n",
    "    # Cases on a given day are a percentage of alerts from 'LAG_DAYS' ago + some noise\n",
    "    base_cases = (pd.Series(alerts).shift(ALERT_TO_CASE_LAG_DAYS) * BASE_CONVERSION_RATE).fillna(0)\n",
    "    case_noise = np.random.randint(-2, 3, size=DATA_PERIOD_DAYS)\n",
    "    cases = np.maximum(0, base_cases + case_noise).astype(int)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({'date': dates, 'alerts': alerts, 'cases': cases})\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    print(\"Sample data generation complete.\\n\")\n",
    "    return df\n",
    "\n",
    "# --- 2. Forecast Future Alerts using SARIMA ---\n",
    "def forecast_future_alerts(df_historical):\n",
    "    \"\"\"\n",
    "    Uses a SARIMA model to forecast the number of alerts for the next N days.\n",
    "    \n",
    "    Args:\n",
    "        df_historical (pd.DataFrame): DataFrame with historical alerts data.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: A series of forecasted alert counts, indexed by future dates.\n",
    "    \"\"\"\n",
    "    print(f\"Training SARIMA model to forecast alerts for the next {FORECAST_PERIOD_DAYS} days...\")\n",
    "    \n",
    "    # SARIMA model parameters. These may need tuning for your specific dataset.\n",
    "    # (p,d,q) are the non-seasonal parameters\n",
    "    # (P,D,Q,m) are the seasonal parameters. m=7 for weekly seasonality.\n",
    "    order = (1, 1, 1)\n",
    "    seasonal_order = (1, 1, 0, 7) if WEEKLY_SEASONALITY else (0, 0, 0, 0)\n",
    "    \n",
    "    # Initialize and fit the SARIMA model\n",
    "    sarima_model = SARIMAX(df_historical['alerts'],\n",
    "                           order=order,\n",
    "                           seasonal_order=seasonal_order,\n",
    "                           enforce_stationarity=False,\n",
    "                           enforce_invertibility=False)\n",
    "    \n",
    "    model_fit = sarima_model.fit(disp=False)\n",
    "    \n",
    "    # Get the forecast for the specified number of future days\n",
    "    forecast_result = model_fit.get_forecast(steps=FORECAST_PERIOD_DAYS)\n",
    "    \n",
    "    # Extract the predicted mean values and ensure they are non-negative\n",
    "    forecasted_alerts = forecast_result.predicted_mean\n",
    "    forecasted_alerts = forecasted_alerts.apply(lambda x: max(0, x)).astype(int)\n",
    "    \n",
    "    print(\"Alert forecasting complete.\\n\")\n",
    "    return forecasted_alerts\n",
    "\n",
    "# --- 3. Model Alert-to-Case Conversion and Predict Future Cases ---\n",
    "def predict_future_cases(df_historical, forecasted_alerts):\n",
    "    \"\"\"\n",
    "    Models the relationship between lagged alerts and cases, then uses this model\n",
    "    to predict future cases based on forecasted alerts.\n",
    "    \n",
    "    Args:\n",
    "        df_historical (pd.DataFrame): DataFrame with historical data.\n",
    "        forecasted_alerts (pd.Series): Series of forecasted alerts.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: A series of forecasted case counts, indexed by future dates.\n",
    "    \"\"\"\n",
    "    print(\"Modeling alert-to-case conversion rate...\")\n",
    "    \n",
    "    # Feature Engineering: Create a lagged alerts column to correlate with cases\n",
    "    df_prepared = df_historical.copy()\n",
    "    df_prepared['alerts_lagged'] = df_prepared['alerts'].shift(ALERT_TO_CASE_LAG_DAYS)\n",
    "    \n",
    "    # Drop rows with NaN values resulting from the shift operation\n",
    "    df_prepared.dropna(inplace=True)\n",
    "    \n",
    "    # Prepare data for Scikit-Learn Linear Regression model\n",
    "    X = df_prepared[['alerts_lagged']] # Feature\n",
    "    y = df_prepared['cases']           # Target\n",
    "    \n",
    "    # Train the linear regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X, y)\n",
    "    \n",
    "    # The learned conversion rate is the model's coefficient\n",
    "    learned_rate = lr_model.coef_[0]\n",
    "    print(f\"Learned Conversion Rate: {learned_rate:.2%}\")\n",
    "    print(\"Predicting future cases based on forecasted alerts...\")\n",
    "\n",
    "    # Predict future cases using the trained model and the forecasted alerts\n",
    "    # We need to reshape the forecasted_alerts series for the model's predict method\n",
    "    future_alerts_reshaped = forecasted_alerts.values.reshape(-1, 1)\n",
    "    predicted_cases = lr_model.predict(future_alerts_reshaped)\n",
    "    predicted_cases = np.maximum(0, predicted_cases).astype(int) # Ensure non-negative\n",
    "    \n",
    "    # Create a pandas Series for the predicted cases with the correct future dates\n",
    "    future_cases_series = pd.Series(predicted_cases, index=forecasted_alerts.index)\n",
    "\n",
    "    print(\"Case prediction complete.\\n\")\n",
    "    return future_cases_series\n",
    "    \n",
    "# --- 4. Visualize the Results ---\n",
    "def plot_forecast(historical_cases, forecasted_cases):\n",
    "    \"\"\"\n",
    "    Plots the historical cases and the forecasted cases on a single graph.\n",
    "    \"\"\"\n",
    "    print(\"Generating forecast plot...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    \n",
    "    # Plot historical data\n",
    "    ax.plot(historical_cases.index, historical_cases, label='Historical Daily Cases', color='royalblue')\n",
    "    \n",
    "    # Plot forecasted data\n",
    "    ax.plot(forecasted_cases.index, forecasted_cases, label='Forecasted Daily Cases', color='darkorange', linestyle='--')\n",
    "    \n",
    "    # Add a vertical line to separate historical from forecasted data\n",
    "    last_historical_date = historical_cases.index[-1]\n",
    "    ax.axvline(x=last_historical_date, color='crimson', linestyle=':', linewidth=2, label='Forecast Start')\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_title(f'Forecast of Daily Case Creation for the Next {FORECAST_PERIOD_DAYS} Days', fontsize=16)\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Number of Cases', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Improve date formatting on the x-axis\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. Get data\n",
    "    historical_df = generate_sample_data()\n",
    "    \n",
    "    # 2. Forecast the driver variable (alerts)\n",
    "    future_alerts_forecast = forecast_future_alerts(historical_df)\n",
    "    \n",
    "    # 3. Use forecasted alerts to predict the target variable (cases)\n",
    "    future_cases_forecast = predict_future_cases(historical_df, future_alerts_forecast)\n",
    "    \n",
    "    # 4. Display the results\n",
    "    print(\"--- Forecast Results ---\")\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'Forecasted_Alerts': future_alerts_forecast,\n",
    "        'Forecasted_Cases': future_cases_forecast\n",
    "    })\n",
    "    print(forecast_df)\n",
    "    print(\"\\n------------------------\\n\")\n",
    "    \n",
    "    # 5. Plot the forecast\n",
    "    plot_forecast(historical_df['cases'], future_cases_forecast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/joemcdougall/opt/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/9l/3n2d6lxj18g2zlvdpv__ptm00000gn/T/pip-install-hy0kfrxy/sklearn/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/9l/3n2d6lxj18g2zlvdpv__ptm00000gn/T/pip-install-hy0kfrxy/sklearn/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/9l/3n2d6lxj18g2zlvdpv__ptm00000gn/T/pip-pip-egg-info-2090lmaq\n",
      "         cwd: /private/var/folders/9l/3n2d6lxj18g2zlvdpv__ptm00000gn/T/pip-install-hy0kfrxy/sklearn/\n",
      "    Complete output (15 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/joemcdougall/opt/anaconda3/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /Users/joemcdougall/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/joemcdougall/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/joemcdougall/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joemcdougall/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joemcdougall/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_mad(data, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Identifies outliers in a dataset using the Median Absolute Deviation (MAD) method.\n",
    "\n",
    "    Args:\n",
    "        data (array-like): A list or numpy array of numerical data\n",
    "                           (e.g., transaction amounts).\n",
    "        threshold (float): The modified Z-score threshold to classify outliers.\n",
    "                           Points with abs(modified Z-score) > threshold are\n",
    "                           considered outliers. Common values are 3.0 or 3.5.\n",
    "                           Defaults to 3.5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - outliers (np.ndarray): An array of the data points identified as outliers.\n",
    "            - median (float): The median of the input data.\n",
    "            - mad (float): The Median Absolute Deviation of the input data.\n",
    "            - modified_z_scores (np.ndarray or None): The calculated modified Z-scores\n",
    "                                                      for each data point, or None if MAD is zero.\n",
    "    \"\"\"\n",
    "# Ensure input is a numpy array for efficient calculations\n",
    "    data = np.asarray(data)\n",
    "\n",
    "    # Handle empty data gracefully\n",
    "    if data.size == 0:\n",
    "        return np.array([]), np.nan, np.nan, np.array([])\n",
    "\n",
    "    # 1. Calculate the median of the data\n",
    "    median = np.median(data)\n",
    "\n",
    "    # 2. Calculate the absolute deviations from the median\n",
    "    # Use np.abs for element-wise absolute value\n",
    "    abs_deviations = np.abs(data - median)\n",
    "\n",
    "    # 3. Calculate the Median Absolute Deviation (MAD)\n",
    "    mad = np.median(abs_deviations)\n",
    "\n",
    "    # 4. Handle the edge case where MAD is zero (e.g., >50% data points are identical)\n",
    "    if mad == 0:\n",
    "        print(\"Warning: MAD is zero. Cannot calculate modified Z-scores.\")\n",
    "        # Option 1: Return no outliers based on Z-score method\n",
    "        # return np.array([]), median, mad, None\n",
    "        # Option 2: Consider any point not equal to the median as an outlier\n",
    "        outliers = data[data != median]\n",
    "        return outliers, median, mad, None\n",
    "\n",
    "\n",
    "    # 5. Calculate the Modified Z-scores\n",
    "    # The constant 0.6745 scales MAD to be comparable to standard deviation\n",
    "    # for normally distributed data.\n",
    "    modified_z_scores = 0.6745 * abs_deviations / mad\n",
    "\n",
    "    # 6. Identify outliers: points where the absolute modified Z-score > threshold\n",
    "    outlier_mask = np.abs(modified_z_scores) > threshold\n",
    "    outliers = data[outlier_mask]\n",
    "\n",
    "    return outliers, median, mad, modified_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transaction Amounts:\n",
      "[  55.2    68.15   75.     88.9   105.5    62.3    79.8    95.1   110.\n",
      "  125.6  4500.     72.5    85.4    99.99  108.2     5.5    91.75  115.3\n",
      "   66.8    81.    103.4  5200.5    78.6    93.25]\n",
      "----------------------------------------\n",
      "Using MAD threshold: 3.5\n",
      "----------------------------------------\n",
      "Data Median: $90.33\n",
      "Data MAD: $16.58\n",
      "[4500.  5200.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample financial transaction amounts ($)\n",
    "# Includes typical amounts and a few potential outliers (very high or low)\n",
    "transaction_amounts = np.array([\n",
    "    55.20, 68.15, 75.00, 88.90, 105.50, 62.30, 79.80, 95.10,\n",
    "    110.00, 125.60, 4500.00, # <-- Likely high outlier\n",
    "    72.50, 85.40, 99.99, 108.20, 5.50,    # <-- Likely low outlier\n",
    "    91.75, 115.30, 66.80, 81.00, 103.40, 5200.50, # <-- Another high outlier\n",
    "    78.60, 93.25\n",
    "])\n",
    "\n",
    "print(\"Original Transaction Amounts:\")\n",
    "print(transaction_amounts)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Set the threshold for outlier detection\n",
    "# A threshold of 3.5 is often used, meaning points more than 3.5\n",
    "# median absolute deviations away from the median are flagged.\n",
    "mad_threshold = 3.5\n",
    "print(f\"Using MAD threshold: {mad_threshold}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Detect outliers using the function\n",
    "identified_outliers, data_median, data_mad, mod_z_scores = detect_outliers_mad(\n",
    "    transaction_amounts,\n",
    "    threshold=mad_threshold\n",
    ")\n",
    "\n",
    "print(f\"Data Median: ${data_median:.2f}\")\n",
    "print(f\"Data MAD: ${data_mad:.2f}\")\n",
    "print(identified_outliers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
