{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca0e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching 5 names from DataFrame A against 6 names from DataFrame B...\n",
      "\n",
      "Found 3 matches with score >= 80:\n",
      "Original Name (A) Matched Name (B)      Score    Method  Index A  Index B\n",
      "       John Smith      Smith, John  95.238095 token_set        0        0\n",
      "   Robert Johnson      Bob Johnson  80.000000 token_set        2        2\n",
      "      Emily Davis   Emily J. Davis 100.000000 token_set        4        4\n",
      "\n",
      "Matches saved to matches.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "def fuzzy_match(df_a, df_b, col_a, col_b, threshold=80, output_file='matches.csv'):\n",
    "    \"\"\"\n",
    "    Matches names from two DataFrames using fuzzy matching.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure columns exist\n",
    "    if col_a not in df_a.columns:\n",
    "        print(f\"Error: Column '{col_a}' not found in DataFrame A\")\n",
    "        return\n",
    "    if col_b not in df_b.columns:\n",
    "        print(f\"Error: Column '{col_b}' not found in DataFrame B\")\n",
    "        return\n",
    "\n",
    "    # Convert to string and handle NaNs\n",
    "    names_a = df_a[col_a].astype(str).fillna('')\n",
    "    names_b = df_b[col_b].astype(str).fillna('')\n",
    "    \n",
    "    # Create a mapping of name -> index/row for lookup if needed, \n",
    "    # but for now we just want to find matches for A in B.\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"Matching {len(names_a)} names from DataFrame A against {len(names_b)} names from DataFrame B...\")\n",
    "    \n",
    "    # Iterate through names in A and find best match in B\n",
    "    for idx, name in names_a.items():\n",
    "        if not name.strip():\n",
    "            continue\n",
    "            \n",
    "        # Approach 1: Token Sort (Good for \"Smith, John\" vs \"John Smith\")\n",
    "        match_sort = process.extractOne(\n",
    "            name, names_b, scorer=fuzz.token_sort_ratio, score_cutoff=threshold\n",
    "        )\n",
    "        \n",
    "        # Approach 2: Token Set (Good for \"John Smith\" vs \"John Smith (CEO)\")\n",
    "        match_set = process.extractOne(\n",
    "            name, names_b, scorer=fuzz.token_set_ratio, score_cutoff=threshold\n",
    "        )\n",
    "\n",
    "        # Logic: Pick the method that gave the higher score\n",
    "        best_match = None\n",
    "        method_used = \"None\"\n",
    "\n",
    "        if match_sort and match_set:\n",
    "            if match_set[1] > match_sort[1]:\n",
    "                best_match = match_set\n",
    "                method_used = \"token_set\"\n",
    "            else:\n",
    "                best_match = match_sort\n",
    "                method_used = \"token_sort\"\n",
    "        elif match_sort:\n",
    "            best_match = match_sort\n",
    "            method_used = \"token_sort\"\n",
    "        elif match_set:\n",
    "            best_match = match_set\n",
    "            method_used = \"token_set\"\n",
    "        \n",
    "        if best_match:\n",
    "            matched_name, score, match_idx = best_match\n",
    "            results.append({\n",
    "                'Original Name (A)': name,\n",
    "                'Matched Name (B)': matched_name,\n",
    "                'Score': score,\n",
    "                'Method': method_used,\n",
    "                'Index A': idx,\n",
    "                'Index B': match_idx\n",
    "            })\n",
    "            \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        print(f\"\\nFound {len(results_df)} matches with score >= {threshold}:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        # Optional: Save to CSV\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nMatches saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"\\nNo matches found above the threshold.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create inline DataFrames\n",
    "    data_a = {\n",
    "        'id': [1, 2, 3, 4, 5],\n",
    "        'name': ['John Smith', 'Jane Doe', 'Robert Johnson', 'Michael Brown', 'Emily Davis']\n",
    "    }\n",
    "    df_a = pd.DataFrame(data_a)\n",
    "\n",
    "    data_b = {\n",
    "        'id': [101, 102, 103, 104, 105, 106],\n",
    "        'full_name': ['Smith, John', 'J. Doe', 'Bob Johnson', 'Mike Brown', 'Emily J. Davis', 'Unmatched Person']\n",
    "    }\n",
    "    df_b = pd.DataFrame(data_b)\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Fuzzy match names between two inline DataFrames.\")\n",
    "    parser.add_argument(\"--threshold\", type=int, default=80, help=\"Matching threshold (0-100)\")\n",
    "    parser.add_argument(\"--output\", default=\"matches.csv\", help=\"Output CSV filename\")\n",
    "    \n",
    "    # Handle running in Jupyter/IPython where sys.argv contains kernel args\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        args = parser.parse_args([])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "    \n",
    "    # Pass the inline dataframes and specify the column names directly\n",
    "    fuzzy_match(df_a, df_b, 'name', 'full_name', args.threshold, args.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0de2e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Original      Matched     Score\n",
      "0      John Smith  Smith, John  90.47619\n",
      "1  Robert Johnson  Bob Johnson  80.00000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def fuzzy_match(df_a, df_b, col_a, col_b, threshold=80):\n",
    "    \"\"\"\n",
    "    Simplified fuzzy matcher using WRatio for robust comparison.\n",
    "    \"\"\"\n",
    "    # 1. Clean data and convert to lists for speed\n",
    "    names_a = df_a[col_a].fillna('').astype(str).tolist()\n",
    "    names_b = df_b[col_b].fillna('').astype(str).tolist()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # 2. Iterate and match\n",
    "    for name in names_a:\n",
    "        if not name.strip(): continue\n",
    "        \n",
    "        # fuzz.WRatio handles \"Smith, John\" vs \"John Smith\" (Sort) \n",
    "        # AND \"John Smith\" vs \"John Smith (CEO)\" (Set) automatically.\n",
    "        match = process.extractOne(\n",
    "            name, names_b, scorer=fuzz.WRatio, score_cutoff=threshold\n",
    "        )\n",
    "        \n",
    "        if match:\n",
    "            # match is a tuple: (matched_string, score, index)\n",
    "            results.append({\n",
    "                'Original': name,\n",
    "                'Matched': match[0],\n",
    "                'Score': match[1]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Usage Example ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_a = pd.DataFrame({'name': ['John Smith', 'Jane Doe', 'Robert Johnson']})\n",
    "    df_b = pd.DataFrame({'full_name': ['Smith, John', 'J. Doe', 'Bob Johnson', 'Unrelated']})\n",
    "\n",
    "    matches = fuzzy_match(df_a, df_b, 'name', 'full_name')\n",
    "    \n",
    "    print(matches)\n",
    "    # matches.to_csv(\"matches.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7822e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input Name   Best Match  Confidence Score\n",
      "0    Cathy Smith  Kathy Smyth         91.818182\n",
      "1  Johnathan Doe     John Doe         85.500000\n",
      "2     Apple Inc.        Apple        100.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import jellyfish\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "class SmartMatcher:\n",
    "    def __init__(self):\n",
    "        # Common noise words for companies and people\n",
    "        self.noise_words = {\n",
    "            'inc', 'corp', 'llc', 'ltd', 'limited', 'company', \n",
    "            'mr', 'mrs', 'ms', 'dr', 'phd', 'jr', 'sr', 'ii', 'iii'\n",
    "        }\n",
    "\n",
    "    def normalize(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # 1. Unicode Normalization (e.g., cafÃ© -> cafe)\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "        \n",
    "        # 2. Lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # 3. Remove punctuation/symbols (keep only letters and numbers)\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "        \n",
    "        # 4. Tokenize and remove noise words\n",
    "        tokens = text.split()\n",
    "        clean_tokens = [t for t in tokens if t not in self.noise_words]\n",
    "        \n",
    "        # Join back; if empty (e.g., input was just \"Inc.\"), revert to original cleaned\n",
    "        return \" \".join(clean_tokens) if clean_tokens else \" \".join(tokens)\n",
    "\n",
    "    def get_match_score(self, name_a, name_b):\n",
    "        \"\"\"\n",
    "        Returns a composite score based on Text Similarity AND Phonetic Similarity.\n",
    "        \"\"\"\n",
    "        clean_a = self.normalize(name_a)\n",
    "        clean_b = self.normalize(name_b)\n",
    "        \n",
    "        if not clean_a or not clean_b:\n",
    "            return 0\n",
    "            \n",
    "        # --- Metric 1: Text Fuzzy Score (WRatio) ---\n",
    "        # WRatio handles partial matches and ordering\n",
    "        text_score = fuzz.WRatio(clean_a, clean_b)\n",
    "        \n",
    "        # --- Metric 2: Phonetic Hedging (Metaphone) ---\n",
    "        # If they sound the same, we boost the score.\n",
    "        # This fixes \"Stephen\" vs \"Steven\" or \"Smith\" vs \"Smyth\"\n",
    "        phone_a = jellyfish.metaphone(clean_a)\n",
    "        phone_b = jellyfish.metaphone(clean_b)\n",
    "        \n",
    "        phonetic_boost = 0\n",
    "        if phone_a and phone_b and phone_a == phone_b:\n",
    "            phonetic_boost = 15  # Bonus points for sounding identical\n",
    "        \n",
    "        # Cap the final score at 100\n",
    "        final_score = min(text_score + phonetic_boost, 100)\n",
    "        \n",
    "        return final_score\n",
    "\n",
    "def match_datasets(df_a, df_b, col_a, col_b, threshold=85):\n",
    "    matcher = SmartMatcher()\n",
    "    \n",
    "    # Pre-calculate normalized B names to speed up lookups\n",
    "    # We store tuples of (OriginalName, CleanName)\n",
    "    b_lookup = [\n",
    "        (original, matcher.normalize(original)) \n",
    "        for original in df_b[col_b].dropna().unique()\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Iterate A\n",
    "    for name_a in df_a[col_a].dropna().unique():\n",
    "        clean_a = matcher.normalize(name_a)\n",
    "        \n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        # Scan B (This can be optimized with blocking for massive datasets)\n",
    "        for original_b, clean_b in b_lookup:\n",
    "            \n",
    "            # Optimization: Quick skip if lengths are wildly different\n",
    "            if abs(len(clean_a) - len(clean_b)) > 5:\n",
    "                continue\n",
    "\n",
    "            # Calculate basic ratio first to avoid expensive phonetic logic if not needed\n",
    "            # (We inline the logic here for performance)\n",
    "            score = fuzz.WRatio(clean_a, clean_b)\n",
    "            \n",
    "            # Apply Phonetic Boost if close but not perfect\n",
    "            if 60 < score < 100:\n",
    "                phone_a = jellyfish.metaphone(clean_a)\n",
    "                phone_b = jellyfish.metaphone(clean_b)\n",
    "                if phone_a == phone_b:\n",
    "                    score += 10 # Boost\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = original_b\n",
    "        \n",
    "        if best_score >= threshold:\n",
    "            results.append({\n",
    "                'Input Name': name_a,\n",
    "                'Best Match': best_match,\n",
    "                'Confidence Score': best_score\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_users = pd.DataFrame({'user': ['Cathy Smith', 'Johnathan Doe', 'Apple Inc.']})\n",
    "    df_db = pd.DataFrame({'db_name': ['Kathy Smyth', 'John Doe', 'Apple']})\n",
    "\n",
    "    matches = match_datasets(df_users, df_db, 'user', 'db_name')\n",
    "    print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "import jellyfish\n",
    "\n",
    "# 1. Setup Dummy Data (Scale this to 100k+ rows)\n",
    "data_a = {\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'name': ['Jonathon Smith', 'Cathy E. Jones', 'Robert White', 'William Black'],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "}\n",
    "\n",
    "data_b = {\n",
    "    'id': [101, 102, 103, 104],\n",
    "    'name': ['Johnathan Smyth', 'Kathy Jones', 'Bob White', 'Bill Black'],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "}\n",
    "\n",
    "df_a = pd.DataFrame(data_a).set_index('id')\n",
    "df_b = pd.DataFrame(data_b).set_index('id')\n",
    "\n",
    "# --- STEP 1: Feature Engineering (The \"Hedge\") ---\n",
    "# We create a 'blocking_key' based on how the name SOUNDS.\n",
    "# This ensures 'Smith' and 'Smyth' end up in the same bucket.\n",
    "\n",
    "def get_phonetic_key(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    # Metaphone is great for English names\n",
    "    return jellyfish.metaphone(text)\n",
    "\n",
    "# Apply to both dataframes\n",
    "# We focus on the last name for blocking (usually more stable)\n",
    "df_a['phonetic_key'] = df_a['name'].apply(lambda x: get_phonetic_key(x.split()[-1]))\n",
    "df_b['phonetic_key'] = df_b['name'].apply(lambda x: get_phonetic_key(x.split()[-1]))\n",
    "\n",
    "print(\"Blocking Keys Created (A):\")\n",
    "print(df_a[['name', 'phonetic_key']])\n",
    "\n",
    "# --- STEP 2: Indexing (The \"Blocker\") ---\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# BLOCK: Only compare rows where 'phonetic_key' is identical.\n",
    "# This reduces comparisons from N*M to a tiny fraction.\n",
    "indexer.block('phonetic_key')\n",
    "\n",
    "# Generate candidate pairs\n",
    "candidate_links = indexer.index(df_a, df_b)\n",
    "\n",
    "print(f\"\\nPairs to compare: {len(candidate_links)} (instead of {len(df_a)*len(df_b)})\")\n",
    "\n",
    "# --- STEP 3: Comparison Logic ---\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "# Exact match on city (High confidence feature)\n",
    "compare_cl.exact('city', 'city', label='city_match')\n",
    "\n",
    "# Fuzzy match on full name (The nuanced check)\n",
    "# 'jarowinkler' is often faster/better for names than Levenshtein\n",
    "compare_cl.string('name', 'name', method='jarowinkler', threshold=0.85, label='name_score')\n",
    "\n",
    "# Compute features for candidate pairs\n",
    "features = compare_cl.compute(candidate_links, df_a, df_b)\n",
    "\n",
    "# --- STEP 4: Scoring & Filtering ---\n",
    "# Simple rule: Must have name match >= 0.85 OR (Name >= 0.7 AND City Match)\n",
    "matches = features[features['name_score'] >= 0.85]\n",
    "\n",
    "# Add the original names back for readability\n",
    "results = matches.copy()\n",
    "results['Name A'] = results.index.map(lambda x: df_a.loc[x[0], 'name']) # Map index level 0\n",
    "results['Name B'] = results.index.map(lambda x: df_b.loc[x[1], 'name']) # Map index level 1\n",
    "\n",
    "print(\"\\n--- Final Matches ---\")\n",
    "print(results[['Name A', 'Name B', 'name_score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
